<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Information Theory | Bounds on the Conditional Entropy</title>
    <meta name="description" content="UvA course">
    <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [ ['$','$'], ['\\(','\\)'] ],processEscapes: true}});</script>
  <script src="/assets/js/MathJax.js?config=TeX-AMS_HTML"></script>
  <script type="application/javascript">function timeout() {setTimeout(function() {MathJax.Hub.Queue(["Typeset", MathJax.Hub]);timeout();}, 1000)};MathJax.Hub.Queue(["Typeset", MathJax.Hub]);timeout();</script>
    
    <link rel="preload" href="/assets/css/styles.c0a0368e.css" as="style"><link rel="preload" href="/assets/js/app.c0a0368e.js" as="script"><link rel="preload" href="/assets/js/12.e1fc2cb5.js" as="script"><link rel="prefetch" href="/assets/js/1.b42459b0.js"><link rel="prefetch" href="/assets/js/10.efcd0718.js"><link rel="prefetch" href="/assets/js/11.b96ece95.js"><link rel="prefetch" href="/assets/js/13.281a42d7.js"><link rel="prefetch" href="/assets/js/14.321f3d63.js"><link rel="prefetch" href="/assets/js/15.2497a21d.js"><link rel="prefetch" href="/assets/js/16.55966313.js"><link rel="prefetch" href="/assets/js/17.99831763.js"><link rel="prefetch" href="/assets/js/18.b2da39df.js"><link rel="prefetch" href="/assets/js/19.783f6fe5.js"><link rel="prefetch" href="/assets/js/2.4174b9dd.js"><link rel="prefetch" href="/assets/js/20.31a487d3.js"><link rel="prefetch" href="/assets/js/21.a011af4c.js"><link rel="prefetch" href="/assets/js/22.e03bc349.js"><link rel="prefetch" href="/assets/js/23.4463ce34.js"><link rel="prefetch" href="/assets/js/24.b076e7c4.js"><link rel="prefetch" href="/assets/js/25.a123cda5.js"><link rel="prefetch" href="/assets/js/26.c5548a4d.js"><link rel="prefetch" href="/assets/js/27.91697a5a.js"><link rel="prefetch" href="/assets/js/28.26582aab.js"><link rel="prefetch" href="/assets/js/29.cc517640.js"><link rel="prefetch" href="/assets/js/3.4c5adbde.js"><link rel="prefetch" href="/assets/js/30.3ca179bc.js"><link rel="prefetch" href="/assets/js/31.3e961e9b.js"><link rel="prefetch" href="/assets/js/32.eb1a29f5.js"><link rel="prefetch" href="/assets/js/33.14f4f43a.js"><link rel="prefetch" href="/assets/js/34.af720415.js"><link rel="prefetch" href="/assets/js/35.d285264b.js"><link rel="prefetch" href="/assets/js/36.44d3152b.js"><link rel="prefetch" href="/assets/js/37.b076d761.js"><link rel="prefetch" href="/assets/js/38.ad1f27c7.js"><link rel="prefetch" href="/assets/js/39.413161ea.js"><link rel="prefetch" href="/assets/js/4.15836b88.js"><link rel="prefetch" href="/assets/js/40.ba4bef5e.js"><link rel="prefetch" href="/assets/js/41.6fbb1017.js"><link rel="prefetch" href="/assets/js/42.80c5b28a.js"><link rel="prefetch" href="/assets/js/43.3f0aeafe.js"><link rel="prefetch" href="/assets/js/44.c08a8e84.js"><link rel="prefetch" href="/assets/js/45.2da068e9.js"><link rel="prefetch" href="/assets/js/46.cf98a01d.js"><link rel="prefetch" href="/assets/js/47.95ad89e2.js"><link rel="prefetch" href="/assets/js/48.11de7b32.js"><link rel="prefetch" href="/assets/js/49.89191d18.js"><link rel="prefetch" href="/assets/js/5.64f16959.js"><link rel="prefetch" href="/assets/js/50.d3c00218.js"><link rel="prefetch" href="/assets/js/51.270d7491.js"><link rel="prefetch" href="/assets/js/52.e303f682.js"><link rel="prefetch" href="/assets/js/53.6b37d452.js"><link rel="prefetch" href="/assets/js/54.5516a56a.js"><link rel="prefetch" href="/assets/js/55.1535f45c.js"><link rel="prefetch" href="/assets/js/56.fe5d6cd5.js"><link rel="prefetch" href="/assets/js/57.c78d418a.js"><link rel="prefetch" href="/assets/js/58.6a5328b4.js"><link rel="prefetch" href="/assets/js/59.9c425111.js"><link rel="prefetch" href="/assets/js/6.56b74cc5.js"><link rel="prefetch" href="/assets/js/60.8471b9ec.js"><link rel="prefetch" href="/assets/js/61.7f1373c2.js"><link rel="prefetch" href="/assets/js/62.3fa31180.js"><link rel="prefetch" href="/assets/js/63.9778d19f.js"><link rel="prefetch" href="/assets/js/64.7ec547c6.js"><link rel="prefetch" href="/assets/js/65.46b6abc2.js"><link rel="prefetch" href="/assets/js/66.41e96d6e.js"><link rel="prefetch" href="/assets/js/67.1e438865.js"><link rel="prefetch" href="/assets/js/68.ec61f597.js"><link rel="prefetch" href="/assets/js/69.a4ad7ed9.js"><link rel="prefetch" href="/assets/js/7.6e55be9c.js"><link rel="prefetch" href="/assets/js/70.ad9257f5.js"><link rel="prefetch" href="/assets/js/71.e45ee61f.js"><link rel="prefetch" href="/assets/js/72.cf56042d.js"><link rel="prefetch" href="/assets/js/73.5190c50f.js"><link rel="prefetch" href="/assets/js/74.a5427366.js"><link rel="prefetch" href="/assets/js/75.ea188344.js"><link rel="prefetch" href="/assets/js/76.69afb87b.js"><link rel="prefetch" href="/assets/js/77.91aca632.js"><link rel="prefetch" href="/assets/js/78.e5c052d0.js"><link rel="prefetch" href="/assets/js/79.a790ac95.js"><link rel="prefetch" href="/assets/js/8.ef38795e.js"><link rel="prefetch" href="/assets/js/80.65aec641.js"><link rel="prefetch" href="/assets/js/81.78289e97.js"><link rel="prefetch" href="/assets/js/82.08de41e8.js"><link rel="prefetch" href="/assets/js/83.ff9c1755.js"><link rel="prefetch" href="/assets/js/84.f86545fe.js"><link rel="prefetch" href="/assets/js/85.c883b25b.js"><link rel="prefetch" href="/assets/js/86.1d29daeb.js"><link rel="prefetch" href="/assets/js/87.9c24da6f.js"><link rel="prefetch" href="/assets/js/88.bcbf388d.js"><link rel="prefetch" href="/assets/js/89.e3aaff55.js"><link rel="prefetch" href="/assets/js/9.3f4a2127.js"><link rel="prefetch" href="/assets/js/90.23eda780.js"><link rel="prefetch" href="/assets/js/91.da84bead.js"><link rel="prefetch" href="/assets/js/92.7d2a6af1.js"><link rel="prefetch" href="/assets/js/93.4de0373f.js">
    <link rel="stylesheet" href="/assets/css/styles.c0a0368e.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div><a href="/" class="home-link router-link-active"><!----><span class="site-name">
      Information Theory
    </span></a><div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""><!----></div><!----></div></header><div class="sidebar-mask"></div><div class="sidebar"><!----><ul class="sidebar-links"><li><div class="sidebar-group first collapsable"><p class="sidebar-heading"><span>general information</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>01 probability theory</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading open"><span>02 entropy</span><span class="arrow down"></span></p><ul class="sidebar-group-items"><li><a href="/02-entropy/jensens-inequality/definition-convexity-and-concavity/" class="sidebar-link">Definition: Convexity and Concavity</a></li><li><a href="/02-entropy/jensens-inequality/jensens-inequality/" class="sidebar-link">Jensen's Inequality</a></li><li><a href="/02-entropy/entropy/definition-shannon-entropy/" class="sidebar-link">Definition: Shannon Entropy</a></li><li><a href="/02-entropy/entropy/definition-binary-entropy/" class="sidebar-link">Definition: Binary Entropy</a></li><li><a href="/02-entropy/entropy/properties-of-shannon-entropy/" class="sidebar-link">Properties of Shannon Entropy</a></li><li><a href="/02-entropy/conditional-entropy/definition-conditional-entropy/" class="sidebar-link">Definition: Conditional Entropy</a></li><li><a href="/02-entropy/conditional-entropy/bounds-on-the-conditional-entropy/" class="active sidebar-link">Bounds on the Conditional Entropy</a></li><li><a href="/02-entropy/conditional-entropy/the-chain-rule/" class="sidebar-link">The Chain Rule</a></li><li><a href="/02-entropy/mutual-information/definition-mutual-information/" class="sidebar-link">Definition: Mutual Information</a></li><li><a href="/02-entropy/entropy-diagrams/entropy-diagrams-for-two-random-variables/" class="sidebar-link">Entropy Diagrams for Two Random Variables</a></li><li><a href="/02-entropy/comparing-two-distributions-relative-and-cross-entropy/definition-relative-entropy/" class="sidebar-link">Definition: Relative Entropy</a></li><li><a href="/02-entropy/comparing-two-distributions-relative-and-cross-entropy/properties-of-relative-entropy/" class="sidebar-link">Properties of Relative Entropy</a></li><li><a href="/02-entropy/comparing-two-distributions-relative-and-cross-entropy/definition-cross-entropy/" class="sidebar-link">Definition: Cross Entropy</a></li></ul></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>03 source coding data compression</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>04 typical sets and encryption</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>05 random processes</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>06 error correction and zero error transmission</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>07 noisy channel coding</span><span class="arrow right"></span></p><!----></div></li></ul></div><div class="page"><div class="content"><h1 id="bounds-on-the-conditional-entropy"><a href="#bounds-on-the-conditional-entropy" aria-hidden="true" class="header-anchor">#</a> Bounds on the Conditional Entropy</h1><p>On this page, we show that the conditional entropy \(H(X|Y)\) is lower bounded by zero, and upper bounded by the entropy \(H(X)\). That is, <em>on average</em> any additional information (i.e., knowing \(Y\)) can only <i>decrease</i> the uncertainty about \(X\).</p><div id="condEntropyBounds" class="content-box pad-box-mini border border-trbl border-round"><h4 style="color: #bc0031;"><strong>Proposition</strong></h4>
Let \(X\) and \(Y\) be random variables with respective images \({\cal X}\) and \(\cal Y\). Then \[ 0 \leq H(X|Y) \leq H(X) \] Equality on the left-hand side holds iff \(X\) is determined by \(Y\), i.e., for all \(y\in {\cal Y}\), there is an \(x\in {\cal X}\) such that \(P_{X|Y}(x|y)=1\). Equality on the right-hand side holds iff \(X\) and \(Y\) are independent.
<p><span role="button" aria-controls="group1" aria-label="Toggler" aria-expanded="false" class="element_toggler"><span class="Button">Proof</span></span></p><div id="group1"><div class="content-box"><p>The lower bound follows trivially from the definition and from <a title="Properties of Shannon Entropy" href="https://canvas.uva.nl/courses/2205/pages/properties-of-shannon-entropy#defPositivity" data-api-endpoint="https://canvas.uva.nl/api/v1/courses/2205/pages/properties-of-shannon-entropy%23defPositivity" data-api-returntype="Page">the positivity of entropy</a>, and so does the characterization of when \(H(X|Y) = 0\).</p><p>For the upper bound, note that \[ H(X|Y) = \sum_{y} P_Y(y) \sum_x P_{X|Y}(x|y) \log\frac{1}{P_{X|Y}(x|y)} = \sum_{x,y} P_{XY}(x,y) \log\frac{P_Y(y)}{P_{XY}(x,y)} \] and \[ H(X) = \sum_x P_{X}(x) \log\frac{1}{P_{X}(x)} = \sum_{x,y} P_{XY}(x,y) \log\frac{1}{P_{X}(x)} \] where the last equality is derived by marginalization. In both expressions, we may restrict the sum to those pairs \((x,y)\) with \(P_{XY}(x,y) &gt; 0\).</p><p>Using Jensen's inequality, it follows that \begin{align} H(X|Y) - H(X) &amp;= \sum_{x,y : P_{XY}(x,y)&gt;0} P_{XY}(x,y)\log \frac{P_X(x)P_Y(y)}{P_{XY}(x,y)} \\ &amp;\leq \log\Bigl( \sum_{x,y : P_{XY}(x,y)&gt;0} P_X(x)P_Y(y) \Bigr) \\ &amp;\leq \log\Bigl( \sum_{x,y} P_X(x)P_Y(y) \Bigr) \\ &amp;= \log\Bigl(\big(\sum_{x \in \mathcal{X}}P_X(x)\big)\big(\sum_{y \in \mathcal{Y}}P_Y(y)\big)\Bigr)\\ &amp;= \log 1 = 0 \, . \end{align} The second inequality follows by the monotonicity of the logarithm function.</p><p>It remains to show that these inequalities are equalities if and only if \(X\) and \(Y\) are independent. Try it yourself first; you can use the equality condition of Jensen's inequality to characterize the first inequality in the derivation above.</p><p><span role="button" aria-controls="group1sub" aria-label="Toggler" aria-expanded="false" class="element_toggler"><span class="Button">Show solution</span></span></p><div id="group1sub"><div class="content-box">We start with the if-direction. Suppose that \(X\) and \(Y\) are independent, i.e., \(P_X(x)P_Y(y) = P_{XY}(x,y)\) for all \((x,y) \in \mathcal{X} \times \mathcal{Y}\). Then for all \((x,y),(x',y') \in \mathcal{X} \times \mathcal{Y}\), \[ \frac{P_X(x)P_Y(y)}{P_{XY}(x,y)} = 1 = \frac{P_X(x')P_Y(y')}{P_{XY}(x',y')}. \] By the equality condition in Jensen's inequality, the first inequality in the derivation above is an equality. The second inequality in the derivation above is easily seen to be equality as well: the second term is bigger only because we add those summands \(P_X(x)P_Y(y)\) for which \(P_{XY}(x,y) = 0\), but for those \(x\) and \(y\), \(P_X(x)P_Y(y) = 0\) as well. For the only-if-direction, suppose that \(H(X|Y) = H(X)\), that is, both inequalities in the above derivation are equalities. Then (from the fact that the second inequality is an equality), we know that whenever \(P_{XY}(x,y) = 0\), also \(P_X(x)P_Y(y) = 0\). When \(P_{XY}(x,y) &gt; 0\), we know from the equality condition in Jensen's inequality that for all \(y' \in \mathcal{Y}\) for which \(P_{XY}(x,y') &gt; 0\), \[ \frac{P_X(x)P_Y(y)}{P_{XY}(x,y)} = \frac{P_X(x)P_Y(y')}{P_{XY}(x,y')}. \] Working out the term \(P_{XY}(x,y)\) as \(P_{X|Y}(x|y)P_Y(y)\) (and similarly for \(P_{XY}(x,y')\)), and cancelling/rearranging terms, we get that \[ P_{X|Y}(x|y) = P_{X|Y}(x|y') \] for all \(y'\) for which \(P_{XY}(x,y') &gt; 0\). From this, we may conclude that \[ P_X(x) = \sum_{y'' \in \mathcal{Y}} P_Y(y'') P_{X|Y}(x|y'') = \sum_{y'' \in \mathcal{Y}} P_Y(y'') P_{X|Y}(x|y) = P_{X|Y}(x|y), \]
where the second inequality follows from the fact that \(P_{X|Y}(x|y) = P_{X|Y}(x|y'')\) for all \(x,y,y''\).
Finally we conclude that \(P_{XY}(x,y) = P_{X|Y}(x|y)P_Y(y) = P_X(x)P_Y(y)\). This equality now holds for all \((x,y) \in \mathcal{X} \times \mathcal{Y}\), so \(X\) and \(Y\) are independent.</div></div></div></div></div></div><!----><div class="content page-nav"><p class="inner"><span class="prev">
        ← <a href="/02-entropy/conditional-entropy/definition-conditional-entropy/" class="prev">
          Definition: Conditional Entropy
        </a></span><span class="next"><a href="/02-entropy/conditional-entropy/the-chain-rule/">
          The Chain Rule
        </a> →
      </span></p></div></div></div></div>
    <script src="/assets/js/12.e1fc2cb5.js" defer></script><script src="/assets/js/app.c0a0368e.js" defer></script>
  </body>
</html>
