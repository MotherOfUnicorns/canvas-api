<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Information Theory | Source-Channel Separation Theorem: Forward Direction</title>
    <meta name="description" content="UvA course">
    <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [ ['$','$'], ['\\(','\\)'] ],processEscapes: true}});</script>
  <script src="/assets/js/MathJax.js?config=TeX-AMS_HTML"></script>
  <script type="application/javascript">function timeout() {setTimeout(function() {MathJax.Hub.Queue(["Typeset", MathJax.Hub]);timeout();}, 1000)};MathJax.Hub.Queue(["Typeset", MathJax.Hub]);timeout();</script>
    
    <link rel="preload" href="/assets/css/styles.c0a0368e.css" as="style"><link rel="preload" href="/assets/js/app.c0a0368e.js" as="script"><link rel="preload" href="/assets/js/87.9c24da6f.js" as="script"><link rel="prefetch" href="/assets/js/1.b42459b0.js"><link rel="prefetch" href="/assets/js/10.efcd0718.js"><link rel="prefetch" href="/assets/js/11.b96ece95.js"><link rel="prefetch" href="/assets/js/12.e1fc2cb5.js"><link rel="prefetch" href="/assets/js/13.281a42d7.js"><link rel="prefetch" href="/assets/js/14.321f3d63.js"><link rel="prefetch" href="/assets/js/15.2497a21d.js"><link rel="prefetch" href="/assets/js/16.55966313.js"><link rel="prefetch" href="/assets/js/17.99831763.js"><link rel="prefetch" href="/assets/js/18.b2da39df.js"><link rel="prefetch" href="/assets/js/19.783f6fe5.js"><link rel="prefetch" href="/assets/js/2.4174b9dd.js"><link rel="prefetch" href="/assets/js/20.31a487d3.js"><link rel="prefetch" href="/assets/js/21.a011af4c.js"><link rel="prefetch" href="/assets/js/22.e03bc349.js"><link rel="prefetch" href="/assets/js/23.4463ce34.js"><link rel="prefetch" href="/assets/js/24.b076e7c4.js"><link rel="prefetch" href="/assets/js/25.a123cda5.js"><link rel="prefetch" href="/assets/js/26.c5548a4d.js"><link rel="prefetch" href="/assets/js/27.91697a5a.js"><link rel="prefetch" href="/assets/js/28.26582aab.js"><link rel="prefetch" href="/assets/js/29.cc517640.js"><link rel="prefetch" href="/assets/js/3.4c5adbde.js"><link rel="prefetch" href="/assets/js/30.3ca179bc.js"><link rel="prefetch" href="/assets/js/31.3e961e9b.js"><link rel="prefetch" href="/assets/js/32.eb1a29f5.js"><link rel="prefetch" href="/assets/js/33.14f4f43a.js"><link rel="prefetch" href="/assets/js/34.af720415.js"><link rel="prefetch" href="/assets/js/35.d285264b.js"><link rel="prefetch" href="/assets/js/36.44d3152b.js"><link rel="prefetch" href="/assets/js/37.b076d761.js"><link rel="prefetch" href="/assets/js/38.ad1f27c7.js"><link rel="prefetch" href="/assets/js/39.413161ea.js"><link rel="prefetch" href="/assets/js/4.15836b88.js"><link rel="prefetch" href="/assets/js/40.ba4bef5e.js"><link rel="prefetch" href="/assets/js/41.6fbb1017.js"><link rel="prefetch" href="/assets/js/42.80c5b28a.js"><link rel="prefetch" href="/assets/js/43.3f0aeafe.js"><link rel="prefetch" href="/assets/js/44.c08a8e84.js"><link rel="prefetch" href="/assets/js/45.2da068e9.js"><link rel="prefetch" href="/assets/js/46.cf98a01d.js"><link rel="prefetch" href="/assets/js/47.95ad89e2.js"><link rel="prefetch" href="/assets/js/48.11de7b32.js"><link rel="prefetch" href="/assets/js/49.89191d18.js"><link rel="prefetch" href="/assets/js/5.64f16959.js"><link rel="prefetch" href="/assets/js/50.d3c00218.js"><link rel="prefetch" href="/assets/js/51.270d7491.js"><link rel="prefetch" href="/assets/js/52.e303f682.js"><link rel="prefetch" href="/assets/js/53.6b37d452.js"><link rel="prefetch" href="/assets/js/54.5516a56a.js"><link rel="prefetch" href="/assets/js/55.1535f45c.js"><link rel="prefetch" href="/assets/js/56.fe5d6cd5.js"><link rel="prefetch" href="/assets/js/57.c78d418a.js"><link rel="prefetch" href="/assets/js/58.6a5328b4.js"><link rel="prefetch" href="/assets/js/59.9c425111.js"><link rel="prefetch" href="/assets/js/6.56b74cc5.js"><link rel="prefetch" href="/assets/js/60.8471b9ec.js"><link rel="prefetch" href="/assets/js/61.7f1373c2.js"><link rel="prefetch" href="/assets/js/62.3fa31180.js"><link rel="prefetch" href="/assets/js/63.9778d19f.js"><link rel="prefetch" href="/assets/js/64.7ec547c6.js"><link rel="prefetch" href="/assets/js/65.46b6abc2.js"><link rel="prefetch" href="/assets/js/66.41e96d6e.js"><link rel="prefetch" href="/assets/js/67.1e438865.js"><link rel="prefetch" href="/assets/js/68.ec61f597.js"><link rel="prefetch" href="/assets/js/69.a4ad7ed9.js"><link rel="prefetch" href="/assets/js/7.6e55be9c.js"><link rel="prefetch" href="/assets/js/70.ad9257f5.js"><link rel="prefetch" href="/assets/js/71.e45ee61f.js"><link rel="prefetch" href="/assets/js/72.cf56042d.js"><link rel="prefetch" href="/assets/js/73.5190c50f.js"><link rel="prefetch" href="/assets/js/74.a5427366.js"><link rel="prefetch" href="/assets/js/75.ea188344.js"><link rel="prefetch" href="/assets/js/76.69afb87b.js"><link rel="prefetch" href="/assets/js/77.91aca632.js"><link rel="prefetch" href="/assets/js/78.e5c052d0.js"><link rel="prefetch" href="/assets/js/79.a790ac95.js"><link rel="prefetch" href="/assets/js/8.ef38795e.js"><link rel="prefetch" href="/assets/js/80.65aec641.js"><link rel="prefetch" href="/assets/js/81.78289e97.js"><link rel="prefetch" href="/assets/js/82.08de41e8.js"><link rel="prefetch" href="/assets/js/83.ff9c1755.js"><link rel="prefetch" href="/assets/js/84.f86545fe.js"><link rel="prefetch" href="/assets/js/85.c883b25b.js"><link rel="prefetch" href="/assets/js/86.1d29daeb.js"><link rel="prefetch" href="/assets/js/88.bcbf388d.js"><link rel="prefetch" href="/assets/js/89.e3aaff55.js"><link rel="prefetch" href="/assets/js/9.3f4a2127.js"><link rel="prefetch" href="/assets/js/90.23eda780.js"><link rel="prefetch" href="/assets/js/91.da84bead.js"><link rel="prefetch" href="/assets/js/92.7d2a6af1.js"><link rel="prefetch" href="/assets/js/93.4de0373f.js">
    <link rel="stylesheet" href="/assets/css/styles.c0a0368e.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div><a href="/" class="home-link router-link-active"><!----><span class="site-name">
      Information Theory
    </span></a><div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""><!----></div><!----></div></header><div class="sidebar-mask"></div><div class="sidebar"><!----><ul class="sidebar-links"><li><div class="sidebar-group first collapsable"><p class="sidebar-heading"><span>general information</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>01 probability theory</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>02 entropy</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>03 source coding data compression</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>04 typical sets and encryption</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>05 random processes</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>06 error correction and zero error transmission</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading open"><span>07 noisy channel coding</span><span class="arrow down"></span></p><ul class="sidebar-group-items"><li><a href="/07-noisy-channel-coding/definition-achievable-rate/" class="sidebar-link">Definition: Achievable Rate</a></li><li><a href="/07-noisy-channel-coding/mathematical-tools/fanos-inequality/" class="sidebar-link">Fano's Inequality</a></li><li><a href="/07-noisy-channel-coding/mathematical-tools/definition-joint-typicality/" class="sidebar-link">Definition: Joint Typicality</a></li><li><a href="/07-noisy-channel-coding/mathematical-tools/joint-asymptotic-equipartition-property-joint-aep/" class="sidebar-link">Joint Asymptotic Equipartition Property (Joint AEP)</a></li><li><a href="/07-noisy-channel-coding/shannons-noisy-channel-coding-theorem/noisy-channel-theorem-forward-direction/" class="sidebar-link">Noisy-Channel Theorem: Forward Direction</a></li><li><a href="/07-noisy-channel-coding/shannons-noisy-channel-coding-theorem/noisy-channel-theorem-converse/" class="sidebar-link">Noisy-Channel Theorem: Converse</a></li><li><a href="/07-noisy-channel-coding/source-channel-separation/source-channel-coding/" class="sidebar-link">Source-Channel Coding</a></li><li><a href="/07-noisy-channel-coding/source-channel-separation/source-channel-separation-theorem-forward-direction/" class="active sidebar-link">Source-Channel Separation Theorem: Forward Direction</a></li><li><a href="/07-noisy-channel-coding/source-channel-separation/source-channel-separation-theorem-converse/" class="sidebar-link">Source-Channel Separation Theorem: Converse</a></li></ul></div></li></ul></div><div class="page"><div class="content"><h1 id="source-channel-separation-theorem-forward-direction"><a href="#source-channel-separation-theorem-forward-direction" aria-hidden="true" class="header-anchor">#</a> Source-Channel Separation Theorem: Forward Direction</h1><p>So far in this course, we have treated the 'encoding' of information from two different perspectives:</p><ul><li>Codes for compressing information (in order to achieve <strong>efficient</strong> communication). <a title="Theorem: Shannon's Source-Coding Theorem (Optimal Codes)" href="https://canvas.uva.nl/courses/2205/pages/theorem-shannons-source-coding-theorem-optimal-codes" data-api-endpoint="https://canvas.uva.nl/api/v1/courses/2205/pages/theorem-shannons-source-coding-theorem-optimal-codes" data-api-returntype="Page">Shannon's source-coding theorem</a> tells us that the minimal codeword length \(\ell_{min}(P_{V^n})\) for encoding a input block from the source \(V^n\) (where all \(V_i\) are i.i.d. according to some distribution \(P_V\)) is lower bounded by \(H(V^n) = nH(V)\). In other words, the rate for such a code, which is \(R = \frac{\log|\mathcal{V}^n|}{n}\), is lower bounded by \(H(V)\).</li><li>Codes for protecting information (in order to achieve <strong>low-error</strong> communication). <a title="Source-Channel Theorem: Converse" href="https://canvas.uva.nl/courses/2205/pages/source-channel-theorem-converse" data-api-endpoint="https://canvas.uva.nl/api/v1/courses/2205/pages/source-channel-theorem-converse" data-api-returntype="Page">Shannon's channel-coding theorem</a> tells us that in order to achieve an arbitrarily low error on the communication over a specific channel, it is necessary that the rate \(R\) is strictly upper bounded by the channel capacity \(C\).</li></ul><p>Combining these two perspectives, we can ask ourselves what happens in the 'sweet spot' where both \(H(V) \leq R\) (as given by the first perspective) and \(R &lt; C\) (as given by the second perspective). Do codes with such \(R\) always exist? The answer turns out to be yes:</p><div class="content-box pad-box-mini border border-trbl border-round"><h4 style="color: #bc0031;"><strong>Theorem: Source-channel separation theorem (forward direction)</strong></h4>
Let \(V_1, V_2, ..., V_n\) be i.i.d. random variables (the source) distributed according to some \(P_V\). Let \((\mathcal{X}, P_{Y|X},\mathcal{Y})\) be a channel with capacity \(C\). If \(H(V) &lt; C\), then there exists a <a title="A source-channel code encodes blocks of source symbols, V^n, into blocks of inputs for the channel, X^n." data-tooltip="{"tooltipClass":"popover popover-padded", "position":"right"}">source-channel code</a> with error probability \(P[\hat{V}^n \neq V^n] \to 0\) as \(n \to \infty\).
<p><span role="button" aria-controls="group7" aria-label="Toggler" aria-expanded="false" class="element_toggler"><span class="Button">Proof</span></span></p><div id="group7"><div class="content-box"><p>The main idea is to construct our code in two steps: first, we optimally compress the source. Then, we apply an error-correcting code to that compression. Let \(0 &lt; \varepsilon &lt; C-H(V)\). We will exhibit a code that has error probability at most \(\varepsilon\). (This immediately implies the existence of such a code for \(\varepsilon \geq C-H(V)\) as well.) For the first part (compression), consider the typical set \(A^{(n)}_{\varepsilon/2}\) for the source \(P_V\). The typical set has size at most \(2^{n(H(V) + \frac{\varepsilon}{2})}\), and, for large enough \(n\), contains at least \(1-\frac{\varepsilon}{2}\) of the probability mass of the source. Hence, we need \(n(H(V)+\frac{\varepsilon}{2})\) bits to compress the source, with a loss (error) of at most \(\frac{\varepsilon}{2}\).</p>
For the second part (error-correction), we just learned that it is possible (for large enough \(n\)) to transmit with error less than \(\frac{\varepsilon}{2}\), as long as \(R &lt; C\). Since we have compressed \(n\) source symbols into \(n(H(V) + \frac{\varepsilon}{2})\) bits, the rate we want to achieve is \(R = H(V) + \frac{\varepsilon}{2}\). By assumption that \(\varepsilon &lt; C - H(V)\), it follows that \(R &lt; C\), such a code indeed exists. Combining the two codes, each with error at most \(\frac{\varepsilon}{2}\), and applying the union bound, we get \begin{align} P[\hat{V}^n \neq V^n] &amp;\leq P[V^n \not\in A^{(n)}_{\varepsilon/2}] + P[\hat{V}^n \neq V^n | V^n \in A^{(n)}_{\varepsilon/2}]\\ &amp;\leq \frac{\varepsilon}{2} + \frac{\varepsilon}{2}\\ &amp;= \varepsilon. \end{align}</div></div></div><p>It is interesting to note that the i.i.d. assumption on the source can be relaxed, and the theorem actually holds for any finite-alphabet stochastic process satisfying the AEP and entropy rate \( H(\{V_i\}) &lt; C \).</p><p></p></div><!----><div class="content page-nav"><p class="inner"><span class="prev">
        ← <a href="/07-noisy-channel-coding/source-channel-separation/source-channel-coding/" class="prev">
          Source-Channel Coding
        </a></span><span class="next"><a href="/07-noisy-channel-coding/source-channel-separation/source-channel-separation-theorem-converse/">
          Source-Channel Separation Theorem: Converse
        </a> →
      </span></p></div></div></div></div>
    <script src="/assets/js/87.9c24da6f.js" defer></script><script src="/assets/js/app.c0a0368e.js" defer></script>
  </body>
</html>
