(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{86:function(t,e,n){"use strict";n.r(e);var a=n(0),o=Object(a.a)({},function(){this.$createElement;this._self._c;return this._m(0)},[function(){var t=this,e=t.$createElement,n=t._self._c||e;return n("div",{staticClass:"content"},[n("h1",{attrs:{id:"the-chain-rule"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#the-chain-rule","aria-hidden":"true"}},[t._v("#")]),t._v(" The Chain Rule")]),n("p",[t._v("The chain rule expresses the relation between the conditional entropy and the joint/maringal entropies of the variables involved. We first state and prove the chain rule for two random variables, and then generalize it to \\(n\\) variables.")]),n("div",{staticClass:"content-box pad-box-mini border border-trbl border-round"},[n("h4",{staticStyle:{color:"#bc0031"}},[n("strong",[t._v("Proposition: Chain Rule")])]),t._v("\nLet \\(X\\) and \\(Y\\) be random variables. Then \\[ H(XY)= H(X) + H(Y|X) \\, . \\]\n"),n("p",[n("span",{staticClass:"element_toggler",attrs:{role:"button","aria-controls":"group2","aria-label":"Toggler","aria-expanded":"false"}},[n("span",{staticClass:"Button"},[t._v("Proof hint")])])]),n("div",{attrs:{id:"group2"}},[n("div",{staticClass:"content-box"},[t._v("We encourage you to try to prove this for yourself. As a starting point, write out the definition of \\(H(XY)\\), and rewrite the terms \\(P_{XY}(x,y)\\) into a conditional form in order to relate it to \\(H(Y|X)\\).\n"),n("p",[n("span",{staticClass:"element_toggler",attrs:{role:"button","aria-controls":"group2sub","aria-label":"Toggler","aria-expanded":"false"}},[n("span",{staticClass:"Button"},[t._v("Show full proof")])])]),n("div",{attrs:{id:"group2sub"}},[n("div",{staticClass:"content-box"},[t._v("The chain rule is a matter of rewriting: \\begin{align} H(XY) &= -\\sum_{x,y} P_{XY}(x,y)\\log P_{XY}(x,y) \\\\ &= -\\sum_{x,y} P_{XY}(x,y)\\log\\bigl(P_X(x)P_{Y|X}(y|x)\\bigr) \\\\ &= -\\sum_{x,y} P_{XY}(x,y) \\log P_X(x) -\\sum_{x,y} P_{XY}(x,y) \\log P_{Y|X}(y|x) \\\\ &= -\\sum_{x}P_X(x)\\log P_X(x) -\\sum_{x,y} P_{XY}(x,y) \\log P_{Y|X}(y|x) \\\\ &= -\\sum_{x}P_X(x)\\log P_X(x) - \\sum_{x} P_X(x)\\sum_{y} P_{Y|X}(y|x) \\log P_{Y|X}(y|x) \\\\ &= H(X) + H(Y|X) \\, . \\end{align} This was to be shown.")])])])])]),n("p",[t._v("The chain rule immediately results in the so-called 'independence bound':")]),n("div",{staticClass:"content-box pad-box-mini border border-trbl border-round"},[n("h4",{staticStyle:{color:"#bc0031"}},[n("strong",[t._v("Corollary: Subadditivity (independence bound)")])]),t._v("\n\\[ H(XY)\\leq H(X)+H(Y) \\, . \\] Equality holds iff \\(X\\) and \\(Y\\) are independent.\n"),n("p",[n("span",{staticClass:"element_toggler",attrs:{role:"button","aria-controls":"group3","aria-label":"Toggler","aria-expanded":"false"}},[n("span",{staticClass:"Button"},[t._v("Proof")])])]),n("div",{attrs:{id:"group3"}},[n("div",{staticClass:"content-box"},[t._v("\\[H(XY) = H(X) + H(Y|X) \\leq H(X) + H(Y),\\] where the equality is due to the chain rule and the inequality is due to "),n("a",{attrs:{href:"https://canvas.uva.nl/courses/2205/pages/bounds-on-the-conditional-entropy#condEntropyBounds%20target="}},[t._v("the upper bound on the conditional entropy")]),t._v(" that \\(H(Y|X) \\leq H(Y)\\) (and equal iff \\(X\\) and \\(Y\\) are independent).")])])]),n("p",[t._v("We can naturally generalize the definition of conditional entropy by applying it to the conditional distribution \\(P_{XY|\\cal A}\\); this results in \\(H(X|Y,{\\cal A})\\), the entropy of \\(X\\) given \\(Y\\) and conditioned on the event \\(\\cal A\\). Since the entropy is a function of the "),n("i",[t._v("distribution")]),t._v(" of a random variable, the chain rule also holds when conditioning on an event \\({\\cal A}\\). Furthermore, it holds that \\[ H(X|YZ) = \\sum_z P_Z(z) H(X|Y,Z\\!=\\!z) \\, , \\] which is straightforward to verify. With this observation, we see that the chain rule generalizes as follows.")]),n("div",{staticClass:"content-box pad-box-mini border border-trbl border-round",attrs:{id:"corGeneralizedChainRule"}},[n("h4",{staticStyle:{color:"#bc0031"}},[n("strong",[t._v("Corollary: generalized chain rule")])]),t._v("\nLet \\(X\\), \\(Y\\) and \\(Z\\) be random variables. Then \\[ H(XY|Z) = H(X|Z) + H(Y|XZ) \\, . \\]")]),n("p",[t._v("Inductively applying the (generalized) chain rule implies that for any sequence \\(X_1,\\ldots,X_n\\) of random variables: \\[ H(X_1\\cdots X_n)= H(X_1) + H(X_2|X_1) + \\cdots + H(X_n|X_{n-1}\\cdots X_1) \\, . \\] Combining this with the upper bound on the conditional entropy, we see that subadditivity generalizes to \\[H(X_1\\cdots X_n)\\leq \\sum_{i=1}^n H(X_i). \\]")])])}],!1,null,null,null);o.options.__file="README.md";e.default=o.exports}}]);