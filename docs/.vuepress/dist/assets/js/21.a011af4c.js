(window.webpackJsonp=window.webpackJsonp||[]).push([[21],{97:function(t,i,n){"use strict";n.r(i);var e=n(0),a=Object(e.a)({},function(){this.$createElement;this._self._c;return this._m(0)},[function(){var t=this.$createElement,i=this._self._c||t;return i("div",{staticClass:"content"},[i("h1",{attrs:{id:"definition-mutual-information"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#definition-mutual-information","aria-hidden":"true"}},[this._v("#")]),this._v(" Definition: Mutual Information")]),i("div",{staticClass:"content-box pad-box-mini border border-trbl border-round"},[i("h4",{staticStyle:{color:"#bc0031"}},[i("strong",[this._v("Definition: Mutual information")])]),this._v("\nLet \\(X\\) and \\(Y\\) be random variables. The mutual information \\(I(X;Y)\\) of \\(X\\) and \\(Y\\) is defined as \\[ I(X;Y)= H(X) - H(X|Y). \\]")]),i("p",[this._v('Thus, in a sense, mutual information reflects the reduction in uncertainty about \\(X\\) when we learn \\(Y\\). Verify the following properties of the mutual information: \\begin{align} I(X;Y) &= H(X) + H(Y) - H(XY)\\\\ I(X;Y) &= I(Y;X) &(``\\text{symmetry}") \\\\ I(X;Y) &\\geq 0 &(``\\text{positivity}") \\\\ I(X;Y) &= 0 \\text{ iff \\(X\\) and \\(Y\\) are independent} \\\\ I(X;X) &= H(X) &(``\\text{self-information}") \\end{align}')])])}],!1,null,null,null);a.options.__file="README.md";i.default=a.exports}}]);