# One-Time Pad

<p>A classic example of a perfectly secure encryption scheme is the one-time pad.</p>
<div class="content-box pad-box-mini border border-trbl border-round">
<h4 style="color: #bc0031;"><strong>Definition: One-time pad (OTP)</strong></h4>
Let the message space \(\mathcal{M}\) be some additive group \((G,+)\). Define the random variable \(K\) to be uniformly distributed over the key space \(\mathcal{K} = \mathcal{M}\), and define the ciphertext space to be \(\mathcal{C} = \mathcal{M}\) as well. Define the encryption and decryption function as follows: \begin{align*} Enc(m,k) &amp;= m + k = c,\\ Dec(c,k) &amp;= c -k = m. \end{align*} Here, \(c-k\) stands for \(c + (-k)\), where \(-k\) is the additive inverse of \(k\) in the group \((G,+)\).</div>
<div class="content-box pad-box-mini border border-trbl border-round">
<h4 style="color: #2d3b45;"><strong>Example: One-time pad for binary strings</strong></h4>
The most common use of the one-time pad is for the group of binary strings under (bit-wise) addition modulo 2, i.e. \((\{0,1\}^n, \oplus)\). In this group, every element is its own additive inverse, resulting in the encryption and decryption functions \begin{align*} Enc(m,k) &amp;= m \oplus k = c,\\ Dec(c,k) &amp;= c \oplus k = m. \end{align*} For example, if \(n=4\), a possible message \(m\) is 0101, and a possible key \(k\) is 0110. The ciphertext \(c\) is \(0101 \oplus 0110 = 0011\), and the decryption of \(c\) is again \(0011 \oplus 0110 = 0101\), the original message \(m\).</div>
<p>We can show that the one-time pad indeed satisfies <a title="Definition: Perfectly Secure Encryption" href="https://canvas.uva.nl/courses/10933/pages/definition-perfectly-secure-encryption" data-api-endpoint="https://canvas.uva.nl/api/v1/courses/10933/pages/definition-perfectly-secure-encryption" data-api-returntype="Page">the definition of perfect security</a>.</p>
<div class="content-box pad-box-mini border border-trbl border-round">
<h4 style="color: #bc0031;"><strong>Theorem</strong></h4>
The one-time pad is perfectly secure.
<p><span class="element_toggler" role="button" aria-controls="group3" aria-label="Toggler" aria-expanded="false"><span class="Button">Proof hint</span></span></p>
<div id="group3" style="">
<div class="content-box">Draw a <a title="Entropy Diagrams for Three Random Variables" href="https://canvas.uva.nl/courses/10933/pages/entropy-diagrams-for-three-random-variables" data-api-endpoint="https://canvas.uva.nl/api/v1/courses/10933/pages/entropy-diagrams-for-three-random-variables" data-api-returntype="Page">three-variable entropy diagram</a> for the random variables \(M\), \(K\), and \(C\). Use the fact that the key\(K\) is picked uniformly at random, and the setup assumption that it is independent from the message \(M\). Then deduce from the diagram that \(I(M;C) = 0\), i.e., the message and ciphertext share no information.
<p><span class="element_toggler" role="button" aria-controls="group2" aria-label="Toggler" aria-expanded="false"><span class="Button">Show full proof</span></span></p>
<div id="group2" style="">
<div class="content-box">Write \(n = \log|G|\). We need to verify that \(I(M;C) = 0\). We do so using a three-variable entropy diagram. We can already fill in the values \(H(K) = n = \log|G|\) (because \(K\) is uniformly distributed), \(H(M|CK) = H(C|MK) = H(K|MC) = 0\) (because each random variable is a function of the other two), and \(I(M;K) = 0\) (this is our setup assumption). 
<p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://canvas.uva.nl/courses/10933/files/1322436/preview?verifier=wm0B9FDH04NiouKfBNbtRLbksaBFQ9rhG4i3u3xP" alt="Entropy diagram for one-time pad" width="240" height="300" data-api-endpoint="https://canvas.uva.nl/api/v1/courses/10933/files/1322436" data-api-returntype="File"></p>
Note that the area of \(I(M;K) = I(M;K|C) + R(M;K;C)\) (shaded orange in the picture) as a whole is 0, but that does not mean that \(I(M;K|C)\) and \(R(M;K;C)\) themselves are zero, because \(R(M;K;C)\) can be negative. We can conclude that there must be some (non-negative) real number \(a \geq 0\) such that \(I(M;K|C) = a\) and \(R(M;K;C) = -a\). As the entropy of \(K\) has to be \(H(K)=n\), we can furthermore conclude that \(I(K;C|M) = n\). From \(I(M;C) \geq 0\) follows that \(x \geq a\), and because \(H(C) \leq n\), it follows that \(x \leq a\) and hence, \(x=a\) and \(I(M;C)=0\), as desired.
<p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://canvas.uva.nl/courses/10933/files/1322437/preview?verifier=rNG9pHArKdiVq0yYhfqo8SZ1WW1jhJLcvY9i2OPF" alt="Entropy diagram for one-time pad" width="247" height="300" data-api-endpoint="https://canvas.uva.nl/api/v1/courses/10933/files/1322437" data-api-returntype="File"></p>
</div>
</div>
</div>
</div>
</div>
<p>We have thus seen that the one-time pad provides perfect information-theoretic security. There is one enormous drawback to this encryption scheme though: the key needs to be as large as the message! To send a message of \(n\) bits, Alice needs to share \(n\) bits of key with Bob. It might be tempting for Alice to reuse the key \(k\) for several messages once she has shared it with Bob, but this is dangerous: Eve could, from two intercepted encryptions \((m_1 + k)\) and \((m_2 + k)\), recover the difference of the two plaintext messages \(m_1 + k - (m_2 + k) = m_1 - m_2\). Already the difference between two plaintext messages can reveal a lot of information about the individual messages, as illustrated in <a href="https://cryptosmith.com/2008/05/31/stream-reuse/">this Cryptosmith blog post</a>.</p>