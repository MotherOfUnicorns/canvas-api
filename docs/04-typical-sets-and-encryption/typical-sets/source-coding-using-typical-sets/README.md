<p>The concept of typical sets is useful for designing codes for a source \(P_X\). Instead of encoding the source symbol-by-symbol, we will encode the source symbols in blocks of \(n\) symbols at a time.</p>
<p>This strategy can be used to design either a lossy or a lossless code. For a lossy code, we notice that with overwhelming probability, a sequence of \(n\) iid samples from \(P_X\) is typical, so it suffices to assign binary labels of length (at most) \(\lceil n (H(X) + \epsilon)\rceil\) to the elements of \(A_{\epsilon}^{(n)}\), and assign some constant (dummy) codeword to all elements outside of the set. Decoding this dummy codeword will result in an error (data loss), but this error occurs with probability at most \(\epsilon\).</p>
<p>The above scheme can be extended to a lossless version by assigning longer labels to the elements outside of \(A_{\epsilon}^{(n)}\), for example binary labels of length \(\lceil \log |\mathcal{X}|^n\rceil = \lceil n \log |\mathcal{X}|\rceil\). An extra 'flag' bit is needed to indicate whether the element is inside or outside the typical set. For large enough \(n\), this code is quite efficient:</p>
<div class="content-box pad-box-mini border border-trbl border-round">
<h4 style="color: #bc0031;"><strong>Theorem</strong></h4>
Let \(X_1, \ldots, X_n\) be i.i.d. real random variables with respect to the set \(\mathcal{X}\), and distributed according to \(P_X\). Let \(\epsilon &gt; 0\). Then there exists a lossless code \(\mathcal{X}^n \to \{0,1\}^*\) such that, for sufficiently large \(n\), \(\mathbb{E}[\frac{1}{n} \ell(X^n)] \leq H(X) + \epsilon\).
<p><span class="element_toggler" role="button" aria-controls="group1" aria-label="Toggler" aria-expanded="false"><span class="Button">Proof</span></span></p>
<div id="group1" style="">
<div class="content-box">Consider the code described above: the code consist of a flag bit (indicating whether or not the element is inside the typical set), followed by either a short label (for elements in the typical set) or a longer one (for elements outside of it). Let \(\epsilon' &gt; 0\) (we will specify the value of \(\epsilon'\) later). Let \(n\) be large enough such that \(P[A_{\epsilon'}^{(n)}] &gt; 1 - \epsilon'\) (see <a title="Properties of Typical Sets" href="https://canvas.uva.nl/courses/2205/pages/properties-of-typical-sets" data-api-endpoint="https://canvas.uva.nl/api/v1/courses/2205/pages/properties-of-typical-sets" data-api-returntype="Page">the second property of typical sets</a>). Then \begin{align} \mathbb{E}[\ell(X^n)] &amp;= \sum_{\vec{x} \in \mathcal{X}^n} P_{X^n}(\vec{x}) \ell(\vec{x})\\ &amp;= \sum_{\vec{x} \in A_{\epsilon'}^{(n)}} P_{X^n}(\vec{x}) \ell(\vec{x}) + \sum_{\vec{x} \not\in A_{\epsilon'}^{(n)}} P_{X^n}(\vec{x}) \ell(\vec{x})\\ &amp;\leq P[A_{\epsilon'}^{(n)}] \cdot (\lceil n (H(X) + \epsilon') \rceil + 1) + P[\overline{A_{\epsilon'}^{(n)}}] \cdot (\lceil n \log |\mathcal{X}| \rceil + 1)\\ &amp;\leq P[A_{\epsilon'}^{(n)}] \cdot (n (H(X) + \epsilon') + 2) + P[\overline{A_{\epsilon'}^{(n)}}] \cdot (n \log |\mathcal{X}| + 2)\\ &amp;\leq n ( H(X) + \epsilon') + \epsilon' \cdot n \log |\mathcal{X}| + 2\\ &amp;= n(H(X) + \epsilon), \end{align} where \(\epsilon = \epsilon' + \epsilon' \log |\mathcal{X}| + \frac{2}{n}\) (note that \(\epsilon\) can be made arbitrarily small by choosing \(\epsilon'\) and \(n\) wisely). The +1 in the first inequality is a consequence of the `flag' bit.</div>
</div>
</div>
<p>For large enough blocks of symbols, the flag bit becomes irrelevant. Typical sets thus allow the construction of an efficient code without the 1 bit of overhead that symbol codes may necessarily have. However, this efficiency is only guaranteed for 'sufficiently large \(n\)', a rather theoretical condition that may not be achievable in practice.</p>
<p>We conclude this chapter by showing that the typical set is in a sense 'optimal', i.e. that picking a smaller set instead of the typical set does not allow for much shorter codewords on average in a lossy setting, not even if we allow rather large error probabilities by allowing about half of the elements to lie outside of the typical set.</p>
<p>Let \(B_{\delta}^{(n)}\) denote the smallest subset of \(\mathcal{X}^n\) such that \(P[B_{\delta}^{(n)}] &gt; 1 - \delta\) (for some parameter \(\delta &gt; 0\)). \(B_{\delta}^{(n)}\) can be explicitly constructed by, for example, ordering \(\mathcal{X}^n\) in order of decreasing probability, and adding elements to \(B_{\delta}^{(n)}\) until the probability threshold of \(1 - \delta\) is reached. The following theorem states that even for large values of \(\delta\), we still need almost \(n H(X)\) bits to denote an element from \(B_{\delta}^{(n)}\).</p>
<div class="content-box pad-box-mini border border-trbl border-round">
<h4 style="color: #bc0031;"><strong>Theorem</strong></h4>
Let \(X_1, \ldots, X_n\) be i.i.d. random variables distributed according to \(P_X\). For any \(\delta &lt; \frac{1}{2}\), and any \(\delta' &gt; 0\), if \(P[B_{\delta}^{(n)}] &gt; 1 - \delta\), then \[ \frac{1}{n} \log |B_{\delta}^{(n)}| &gt; H(X) - \delta', \] for sufficiently large \(n\).
<p><span class="element_toggler" role="button" aria-controls="group2" aria-label="Toggler" aria-expanded="false"><span class="Button">Proof</span></span></p>
<div id="group2" style="">
<div class="content-box">Let \(\delta,\epsilon &lt; \frac{1}{2}\), and consider some \(B_{\delta}^{(n)}\) such that \(P[B_{\delta}^{(n)}] &gt; 1 - \delta\). By <a title="Properties of Typical Sets" href="https://canvas.uva.nl/courses/2205/pages/properties-of-typical-sets" data-api-endpoint="https://canvas.uva.nl/api/v1/courses/2205/pages/properties-of-typical-sets" data-api-returntype="Page">the second property of typical sets</a>, \(P[A_{\epsilon}^{(n)}] &gt; 1 - \epsilon\), for large enough \(n\). Thus, by the union bound, \begin{align} 1 - \epsilon - \delta &amp;&lt; 1 - P[\overline{A_{\epsilon}^{(n)}}] - P[\overline{B_{\delta}^{(n)}}]\\ &amp;\leq 1-P[\overline{A_{\epsilon}^{(n)}} \cup \overline{B_{\delta}^{(n)}}]\\ &amp;= P[A_{\epsilon}^{(n)} \cap B_{\delta}^{(n)}]\\ &amp;= \sum_{\vec{x} \in A_{\epsilon}^{(n)} \cap B_{\delta}^{(n)}} P_{X^n}(\vec{x})\\ &amp;\leq \sum_{\vec{x} \in A_{\epsilon}^{(n)} \cap B_{\delta}^{(n)}} 2^{-n(H(X) - \epsilon)}\\ &amp;= |A_{\epsilon}^{(n)} \cap B_{\delta}^{(n)}| \cdot 2^{-n(H(X) - \epsilon)}\\ &amp;\leq |B_{\delta}^{(n)}| \cdot 2^{-n(H(X) - \epsilon)}. \end{align} Rearranging this expression and taking the logarithm, we get \begin{align} H(X) - \epsilon + \frac{1}{n} \log (1 - \epsilon - \delta) &lt; \frac{1}{n} \log |B_{\delta}^{(n)}|. \end{align} If we now set \(\delta' := \epsilon - \frac{1}{n} \log (1 - \epsilon - \delta)\), then \begin{align} H(X) - \delta' &lt; \frac{1}{n} \log |B_{\delta}^{(n)}|, \end{align} as desired. Observe that we can make the expression for \(\delta'\) as small as desired by choosing a small enough \(\epsilon&gt;0\) and a large enough \(n\), even if \(\delta\) is rather large.</div>
</div>
</div>
<p>Â </p>