<p><img src="413835" alt="RandomProcess.png" width="600" height="488" data-api-endpoint="https://canvas.uva.nl/api/v1/courses/2205/files/413835" data-api-returntype="File"></p>
<p>Suppose that we run the process of <a href="https://canvas.uva.nl/courses/2205/pages/markov-process-time-invariance-finite-state-transition-matrix#example2" data-api-endpoint="https://canvas.uva.nl/api/v1/courses/2205/pages/markov-process-time-invariance-finite-state-transition-matrix%23example2" data-api-returntype="Page">Example 2</a> for a very large number of steps, and wonder what the probability will be of observing an \(\texttt{a}\) at the next step. Given the initial distribution and the state diagram, we can compute the probability distribution for every \(X_i\). In the figure above, \(P_{X_i}(\texttt{a})\) is plotted for several values of \(i\). The probability to observe an \(\texttt{a}\) seems to stabilize. This leads us to the following definition:</p>
<div class="content-box pad-box-mini border border-trbl border-round">
<h4 style="color: #bc0031;"><strong>Definition: Stationary distribution</strong></h4>
A stationary distribution for a time-invariant Markov chain is a distribution \(P_{X_n}\) such that \(P_{X_{n+1}} = P_{X_n}\).</div>
<p>If the initial distribution of a time-invariant Markov process is stationary, then the entire process is stationary as <a title="Stationary Process" href="https://canvas.uva.nl/courses/2205/pages/stationary-process" data-api-endpoint="https://canvas.uva.nl/api/v1/courses/2205/pages/stationary-process" data-api-returntype="Page">defined previously</a>.</p>
<div class="content-box pad-box-mini border border-trbl border-round">
<h4 style="color: #bc0031;"><strong>Proposition</strong></h4>
Every time-invariant finite-state Markov process has a stationary distribution.
<p><span class="element_toggler" role="button" aria-controls="group12" aria-label="Toggler" aria-expanded="false"><span class="Button">Proof</span></span></p>
<div id="group12" style="">
<div class="content-box">Let \(k:= |\mathcal{X}|\). The \(k \times k\) transition matrix \(R\) with entries \(R_{ij} = P_{X_{n+1}|X_n}(j|i)\) is a <a href="https://en.wikipedia.org/wiki/Stochastic_matrix">stochastic matrix</a>, as for every row \(i\), the sum over columns is \(\sum_{j=1}^k R_{ij} = 1\). We are interested in finding a vector \(v \in \mathbb{R}_{\geq 0}^k\) such that \(\|v\| = 1\) and \(R^Tv = v\). This vector then represents the stationary distribution. Clearly, a possible eigenvector for \(R\) is the all-1 vector \(w=(1,\ldots,1)^T\) because \(R w = w\) by definition of a stochastic matrix. Hence, 1 is an eigenvalue of \(R\). As \(R\) and \(R^T\) <a href="https://math.stackexchange.com/questions/123923/a-matrix-and-its-transpose-have-the-same-set-of-eigenvalues/123927">have the same eigenvalues</a>, 1 is also an eigenvalue of \(R^T\); let \(v \in \mathbb{R}^k\) be the corresponding eigenvector such that \(R^T v = v\). If all coordinates of \(v\) are non-negative, one can verify that we have found a stationary distribution by renormalizing \(v / \sum_{i=1}^k v_i\). Otherwise, let us write \(v = v^+ - v^-\) with \(v^+,v^- \in \mathbb{R}_{\geq 0}^k\), where we put all positive coordinates of \( v \) in \(v^+\) and all negative coordinates of \( v \) in \(v^-\).Â  Note that \(R^T v^+ - R^T v^- = R^T (v^+ - v^-) = R^T v = v = v^+ - v^-\). As all entries of \(R^T, v^+\) and \(v^-\) are positive, equality must hold for both the positive and negative parts: \(R^T v^+ = v^+\) and \(R^T v^- = v^-\). As either \(v^+ \neq 0^k\) or \(v^- \neq 0^k\) (otherwise \(v = 0^k\), which cannot be the case for an eigenvector), renormalizing that non-zero vector as above yields the stationary distribution.</div>
</div>
</div>
<p>Given the transition matrix \(R\) of a finite-state Markov process, one can find the stationary distribution \( \mu \) by solving the linear equation \( \mu R = \mu \) under the constraint that \( \sum_i \mu_i = 1\).</p>
<div class="content-box pad-box-mini border border-trbl border-round">
<h4 id="example2" style="color: #2d3b45;"><strong>Example 2: A finite-state time-invariant Markov process, continued</strong></h4>
The matrix representation of the process above is given by \[ R = \left[ \begin{array}{c c} 0.7&amp;0.3\\ 0.5&amp;0.5 \end{array} \right] \] . Writing out \( (\mu_a, \mu_b) R = (\mu_a, \mu_b) \) results in \[ \left\{ \begin{array}{l} 0.7 \mu_a + 0.5 \mu_b = \mu_a \\ 0.3 \mu_a + 0.5 \mu_b = \mu_b \end{array} \right. \]. These are linearly dependent equations, but together with the constraint \( \mu_a + \mu_b = 1 \), they can be solved to \( (\mu_a , \mu_b) = (5/8, 3/8) \).</div>