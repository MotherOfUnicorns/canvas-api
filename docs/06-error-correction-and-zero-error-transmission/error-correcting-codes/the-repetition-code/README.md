<p>A simple and intuitive code is the \(n\)-bit <span style="color: #bc0031;"><strong>repetition code</strong></span> \(R_n\): a single message bit is encoded by simply repeating the bit \(n\) times. Decoding is done by majority vote, that is, \(\mathtt{dec}(y) = MAJ(y_1, \ldots, y_n)\), which is 1 if and only if (strictly) more than half of the bits in \(y\) are 1s. In order to avoid ties in the decoding, repetition codes usually require that \(n\) is odd.</p>
<div class="content-box pad-box-mini border border-trbl border-round">
<h4 style="color: #2d3b45;"><strong>Example: 3-bit repetition code</strong></h4>
Consider the 3-bit repetition code \(R_3\). It is a (2,3) code with codebook \(\{000,111\}\). The rate of \(R_3\) is \(1/3\). The probability of error for the message \(w = 0\), sent over a BSC with bit flip propability \(f\), is \begin{align*} \lambda_0 &amp;= P[\mathtt{dec}(Y^n) \neq 0 \mid X^n = 000]\\ &amp;= P[Y^n = 011 \ \cup \ Y^n = 101 \ \cup \ Y^n = 110 \ \cup \ Y^n = 111 \mid X^n = 000]\\ &amp;= 3f^2(1-f) + f^3. \end{align*} A similar calculation shows that \(\lambda_1 = \lambda_0\). Hence, the maximal and average probability of error are equal to \(\lambda_0\) as well. As a concrete example, if \(f = 0.1\), the 3-bit repetition code has an error probability of approximately 0.03. Hence, the 3-bit repetition code provides an error probability that is about three times lower (\(3\%\) instead of \(10\%\)), at the expense of a rate that is a factor 3 worse than simply sending the messages through the channel without encoding.</div>
<p>In general, the \(n\)-bit repetition code is a \((2,n)\) code with the relatively low rate of \(1/n\) and an average/maximal probability of error of \[ \sum_{k=(n+1)/2}^n {n \choose k} f^k (1-f)^{n-k} \] when used on a binary symmetric channel with bit flip probability \(f\).</p>